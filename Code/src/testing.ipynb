{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from train import train_rbf_simple\n",
    "from utils import generate_migrants\n",
    "from utils import calculate_thresholds_basic\n",
    "from migrant_detection import predict_migrant_linear\n",
    "from migrant_detection import adaptive_threshold\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test basic migrant dection on linearly seperable dataset with linear SVM still included for the Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\"insert dataset\")\n",
    "clf = load(\"insert model\")\n",
    "# Generate 10 migrants and a datapoint for each year since the migration\n",
    "n=10\n",
    "migrants = generate_migrants(data, n)\n",
    "\n",
    "migrant = migrants[0]\n",
    "# Extract the first two dimensions for plotting\n",
    "x = migrant[:, 0].flatten()\n",
    "y = migrant[:, 1].flatten()\n",
    "cluster_0 = data[data['cluster'] == 0].drop(columns=['cluster'])\n",
    "cluster_1 = data[data['cluster'] == 1].drop(columns=['cluster'])\n",
    "x1 = data['87Sr/86Sr']\n",
    "y1 = data['208Pb/204Pb']\n",
    "plt.scatter(x1,y1)\n",
    "\n",
    "# Generate basic threshold for distance to hyperplane(t1) and distance to cluster connecting vector(t2)\n",
    "t1, t2 = calculate_thresholds_basic(data, clf)\n",
    "\n",
    "# Drop labels\n",
    "data = data.drop(columns=['cluster'])\n",
    "\n",
    "predictions_migrant = predict_migrant_linear(migrant, data, clf, t1, t2)\n",
    "print(predictions_migrant)\n",
    "\n",
    "# Plot detected migrants\n",
    "plt.scatter(x[0:20], y[0:20], c=predictions_migrant, cmap='viridis')\n",
    "\n",
    "# Plot support vectors\n",
    "support = np.array([[x[0],x[1], 3] for x in clf.support_vectors_]) #np.append(np.array(clf.support_vectors_),[[3],[3]],axis=1)\n",
    "plt.scatter(support[:,0], support[:,1], c='red', cmap='viridis')\n",
    "#plot.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Migrant prediction on cluster - still included for the visualization\n",
    "data = load(\"insert dataset\")\n",
    "clf = load(\"insert model\")\n",
    "\n",
    "data_no_cluster = data.drop(columns=['cluster'])\n",
    "\n",
    "# Extract the first two dimensions for plotting\n",
    "x1 = data['87Sr/86Sr']\n",
    "y1 = data['208Pb/204Pb']\n",
    "plt.scatter(x1,y1)\n",
    "\n",
    "# Generate basic threshold for distance to hyperplane(t1) and distance to cluster connecting vector(t2)\n",
    "t1, t2 = calculate_thresholds_basic(data, clf)\n",
    "\n",
    "# Drop labels\n",
    "data = data.drop(columns=['cluster'])\n",
    "\n",
    "predictions_migrant = predict_migrant_linear(data_no_cluster.values, data, clf, t1, t2)\n",
    "print(predictions_migrant)\n",
    "\n",
    "# Plot detected migrants\n",
    "plt.scatter(x1, y1, c=predictions_migrant, cmap='viridis')\n",
    "\n",
    "# Plot support vectors\n",
    "support = np.array([[x[0],x[1], 3] for x in clf.support_vectors_]) #np.append(np.array(clf.support_vectors_),[[3],[3]],axis=1)\n",
    "plt.scatter(support[:,0], support[:,1], c='red', cmap='viridis')\n",
    "#plot.scatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Migrant Generation from generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included for the visualization\n",
    "data = load(\"insert dataset\")\n",
    "n=1\n",
    "migrants = generate_migrants(data, n)\n",
    "# Extract the first two dimensions for plotting\n",
    "x = migrants[:, :, 0].flatten()\n",
    "y = migrants[:, :, 1].flatten()\n",
    "cluster_0 = data[data['cluster'] == 0].drop(columns=['cluster'])\n",
    "cluster_1 = data[data['cluster'] == 1].drop(columns=['cluster'])\n",
    "\n",
    "x1 = data['87Sr/86Sr']\n",
    "y1 = data['208Pb/204Pb']\n",
    "plt.scatter(x1,y1)\n",
    "#sns.kdeplot(data=cluster_0, x='87Sr/86Sr', y='208Pb/204Pb')\n",
    "#sns.kdeplot(data=cluster_1, x='87Sr/86Sr', y='208Pb/204Pb')\n",
    "# Create an array of colors based on the year (from 0 to 19)\n",
    "colors = np.tile(np.arange(20), n)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y, c=colors, cmap='magma')\n",
    "# Plot single migrant\n",
    "#plt.scatter(x[10], y[10], c='red')\n",
    "# Add labels and title\n",
    "plt.xlabel('87Sr/86Sr')\n",
    "plt.ylabel('208Pb/204Pb')\n",
    "#plt.title('Process if linear Mixing after Migration')\n",
    "\n",
    "# Show colorbar for reference\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Year')\n",
    "\n",
    "# Display the plot\n",
    "#plt.show()\n",
    "#plt.savefig('linear_mixing_process.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''# Look at preparatory experiments for threshold calculations\n",
    "from pprint import pprint\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = load (\"experiment_result/preparatory_experiment_threshold_3_multiplier_fine_tuning.pkl\")\n",
    "print(results.copy().groupby(['Multiplier']).mean().groupby(['Seed']).mean())\n",
    "results = results.drop(columns=['Seed'])\n",
    "results = results.rename(columns={\"Score\": \"F1-Score\"})\n",
    "results = results.groupby(['Multiplier']).mean()\n",
    "sns.lineplot(results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distance distributions\n",
    "#%pip install statsmodels # install statsmodels if needed\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "#data = np.array(load('Plots/distances_cluster_0.pkl'))\n",
    "data = np.array(load('Plots/distances_cluster_1.pkl'))\n",
    "#data = load('Plots/distances_ccv_[0.89797944 0.18919623 0.08775629 0.19234022 0.27453981 0.14073406].pkl')\n",
    "#data = np.array(load('Plots/distances_ccv_[0.89797944 0.18919623 0.08775629 0.19234022 0.27453981 0.14073406].pkl'))\n",
    "std = np.std(data)\n",
    "mean = np.mean(data)\n",
    "stats.skew(data)\n",
    "stats.kurtosis(data,fisher=False)\n",
    "cols =['Distance to CCV']\n",
    "#data = pd.DataFrame(data,columns= cols)\n",
    "#sns.displot(data, x=cols[0], kind='kde')\n",
    "#plt.savefig(\"Distances_ccv_kde_plot_c1.svg\")\n",
    "\n",
    "sm.qqplot(data, line='s') \n",
    "#plt.show() \n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111)\n",
    "#res = stats.probplot(data, plot=sns.mpl.pyplot)\n",
    "\n",
    "#ax.set_title(\"Probability Plot for the Distances of Cluster 1 to the CCV\")\n",
    "\n",
    "#plt.savefig(\"Distances_ccv_qq_plot_c1.svg\")\n",
    "#plt.show()\n",
    "'''\n",
    "g = sns.displot(\n",
    "    data, \n",
    "    x=cols[0],\n",
    "    kind='kde',\n",
    "    facet_kws=dict(sharey=False, sharex=False)\n",
    ")\n",
    "# extract and flatten the axes from the figure\n",
    "axes = g.axes.flatten()\n",
    "\n",
    "# iterate through each axes\n",
    "for ax in axes:\n",
    "    # extract the species name\n",
    "    #spec = ax.get_title().split(' = ')[1]\n",
    "    \n",
    "    # select the data for the species\n",
    "    #data = pen_g.loc[spec, :]\n",
    "    \n",
    "    # print data as needed or comment out\n",
    "    #print(data)\n",
    "    \n",
    "    # plot the lines\n",
    "    ax.axvline(x=mean, c='k', ls='-', lw=1.8)\n",
    "    ax.axvline(x=mean + std, c='yellow', ls='--', lw=1.8)\n",
    "    ax.axvline(x=mean - std, c='yellow', ls='--', lw=1.8)\n",
    "\n",
    "    ax.axvline(x=mean + 2*std, c='orange', ls='--', lw=1.8)\n",
    "    ax.axvline(x=mean - 2*std, c='orange', ls='--', lw=1.8)\n",
    "\n",
    "    ax.axvline(x=mean + 3*std, c='red', ls='--', lw=1.8)\n",
    "    ax.axvline(x=mean - 3*std, c='red', ls='--', lw=1.8)\n",
    "\n",
    "plt.savefig(\"Distances_ccv_kde_plot_quantiles_c1.svg\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''# Look at Experiment 2 Results Cluster Size\n",
    "from pprint import pprint\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = load('experiment_result/experiment03_unbalanced_clusters.pkl') \n",
    "results = results.drop(columns=['Seed'])\n",
    "results = results.rename(columns={\"Score\": \"F1-Score\"})\n",
    "results = results.groupby(['Samples']).mean()\n",
    "results = results.reset_index()\n",
    "\n",
    "ax = sns.pointplot(data = pd.melt(results, ['Samples'], var_name = 'Metric', value_name = 'Score'), x='Samples', y='Score', hue='Metric')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.xticks(rotation=45)\n",
    "#ax.set_xticks(['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000'])\n",
    "#ax.set_xticks(range(13), labels=['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000']) # <--- set the ticks first\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Experiment 1 Migration Progress Groups of Years\n",
    "from pprint import pprint\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "results = load('experiment_result/experiment01_groups_of_years_seeds_multiplier_1_5.pkl')\n",
    "results = results.drop(columns=['Mahalanobis_migrant_c0', 'Mahalanobis_migrant_c1', 'Min_Mahalanobis', 'Mahalanobis_c0', 'Mahalanobis_c1'])\n",
    "\n",
    "cols = ['Start_Year', 'End_Year']\n",
    "results['Years'] = results[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "results = results.drop(columns=cols)\n",
    "results = results.drop(columns=['Seed'])\n",
    "results = results.rename(columns={\"Score\": \"F1-Score\"})\n",
    "results = results.groupby(['Years']).mean()\n",
    "results = results.reset_index()\n",
    "print(results)\n",
    "\n",
    "order = [\"1-4\", \"5-8\", \"9-12\", \"13-16\", \"16-20\"]\n",
    "ax = sns.pointplot(data = pd.melt(results, ['Years'], var_name = 'Metric', value_name = 'Score'), x='Years', y='Score', hue='Metric', order=order)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.set(ylim=(0.5, 1.01))\n",
    "plt.xticks(rotation=45)\n",
    "#ax.set_xticks(['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000'])\n",
    "#ax.set_xticks(range(13), labels=['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000']) # <--- set the ticks first\n",
    "plt.show()\n",
    "columns=['Seed', 'Start_Year', 'End_Year', 'Mahalanobis_migrant_c0', 'Mahalanobis_migrant_c1', 'Min_Mahalanobis', 'Mahalanobis_c0', 'Mahalanobis_c1', 'Accuracy', 'Recall', 'Precision', 'Score']\n",
    "columns=['Seed', 'Start_Year', 'End_Year', 'Accuracy', 'Recall', 'Precision', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''# Look at Experiment 1 Migration Progress per Year\n",
    "from pprint import pprint\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "results = load(\"experiment_result/experiment01_per_years_seeds_multiplier_2.pkl\")\n",
    "# Mahalanobis Distance Visualization\n",
    "results = results.drop(columns=['End_Year'])\n",
    "results = results.drop(columns=['Seed'])\n",
    "results['Min_Mahalanobis'] = results['Min_Mahalanobis'].apply(np.mean)\n",
    "\n",
    "results = results.drop(columns=[ 'Migrant_Prediction', 'Mahalanobis_migrant_c0', 'Mahalanobis_migrant_c1', 'Mahalanobis_c0', 'Mahalanobis_c1'])\n",
    "results = results.groupby(['Start_Year']).mean()\n",
    "results = results.reset_index()\n",
    "results = results.rename(columns={\"Start_Year\": \"Year\", \"Min_Mahalanobis\": \"Mahalanobis Distance\"})\n",
    "sns.pointplot( data = results, x='Year', y='Mahalanobis Distance')\n",
    "#ax = sns.pointplot(data = pd.melt(results, ['Year'], var_name = 'Data', value_name = 'Mahalanobis Distance'), x='Year', y='Mahalanobis Distance', hue='Metric')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\"\"\"\n",
    "# Average Prediction of Migrant\n",
    "results = results.drop(columns=['End_Year'])\n",
    "results = results.drop(columns=['Seed'])\n",
    "results['Migrant_Prediction'] = results['Migrant_Prediction'].apply(np.sum)\n",
    "results = results.drop(columns=[ 'Min_Mahalanobis', 'Mahalanobis_migrant_c0', 'Mahalanobis_migrant_c1', 'Mahalanobis_c0', 'Mahalanobis_c1'])\n",
    "results = results.groupby(['Start_Year']).mean()\n",
    "results = results.reset_index()\n",
    "sns.pointplot( data = results, x='Start_Year', y='Migrant_Prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Metric Visualization\n",
    "results = results.drop(columns=[ 'Migrant_Prediction', 'Mahalanobis_migrant_c0', 'Mahalanobis_migrant_c1', 'Min_Mahalanobis', 'Mahalanobis_c0', 'Mahalanobis_c1'])\n",
    "print(results.copy().groupby(['Start_Year']).mean())\n",
    "print(results.copy().groupby(['Start_Year']).mean().groupby(['Seed']).mean())\n",
    "#sns.barplot(results, x='Samples', y='Recall')\n",
    "#plt.show()\n",
    "#cols = ['Start_Year', 'End_Year']\n",
    "#results['Years'] = results[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "results = results.drop(columns=['End_Year'])\n",
    "results = results.drop(columns=['Seed'])\n",
    "results = results.rename(columns={\"Score\": \"F1-Score\", \"Start_Year\": \"Year\"})\n",
    "#results = results[results['Samples']<1000]\n",
    "results = results.groupby(['Year']).mean()\n",
    "results = results.reset_index()\n",
    "print(results)\n",
    "\n",
    "#sns.pointplot(data = results, x=results.index, y='F1-Score')\n",
    "#sns.pointplot(data = results, x=results.index, y='Recall')\n",
    "ax = sns.pointplot(data = pd.melt(results, ['Year'], var_name = 'Metric', value_name = 'Score'), x='Year', y='Score', hue='Metric')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "#ax.set(ylim=(0.5, 1.01))\n",
    "plt.xticks(rotation=45)\n",
    "#ax.set_xticks(['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000'])\n",
    "#ax.set_xticks(range(13), labels=['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000']) # <--- set the ticks first\n",
    "plt.show()\n",
    "\"\"\"\n",
    "columns = ['Seed', 'Start_Year', 'End_Year', 'Migrant_Prediction' ,'Mahalanobis_migrant_c0', 'Mahalanobis_migrant_c1', 'Min_Mahalanobis', 'Mahalanobis_c0', 'Mahalanobis_c1', 'Accuracy', 'Recall', 'Precision', 'Score']\n",
    "\n",
    "columns=['Seed', 'Start_Year', 'End_Year', 'Accuracy', 'Recall', 'Precision', 'Score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Look at results for Experiment Spread Differences\n",
    "from pprint import pprint\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "results = load('experiment_result/experiment04_Spread_Differences_C10E10_rbf.pkl')\n",
    "print(results.copy().groupby(['Multiplier for STD']).mean())\n",
    "print(results.copy().groupby(['Multiplier for STD']).mean().groupby(['Seed']).mean())\n",
    "results = results.drop(columns=['Seed','Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 0\",\"Confusion Matrix\"])\n",
    "results = results.rename(columns={\"Score\": \"F1-Score\"})\n",
    "results = results.groupby(['Multiplier for STD']).mean()\n",
    "results = results.reset_index()\n",
    "\n",
    "ax = sns.pointplot(data = pd.melt(results, ['Multiplier for STD'], var_name = 'Metric', value_name = 'Score'), x='Multiplier for STD', y='Score', hue='Metric')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "#ax.set(ylim=(0.5, 1.01))\n",
    "plt.xticks(rotation=45)\n",
    "#ax.set_xticks(['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000'])\n",
    "#ax.set_xticks(range(13), labels=['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000']) # <--- set the ticks first\n",
    "plt.show()\n",
    "\n",
    "columns = ['Seed', 'Multiplier for STD','Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 0\",\"Confusion Matrix\", 'Accuracy', 'Recall', 'Precision', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results for Experiment Spread Differences additional infos\n",
    "from pprint import pprint\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "results = load('experiment_result/experiment04_Spread_Differences_10E10_rbf_additional_Infos.pkl')\n",
    "results.columns = ['Seed', 'Multiplier for STD','Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 1\",\"Confusion Matrix\", 'Accuracy', 'Recall', 'Precision', 'Score', 'SVM F1-Score', 'Number of overlapping Dimensions']\n",
    "\n",
    "results = results.drop(columns=['Seed', 'Accuracy', 'Recall', 'Precision', 'Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 1\",\"Confusion Matrix\", \"Score\", 'SVM F1-Score'])\n",
    "\n",
    "results = results.groupby(['Multiplier for STD']).mean()\n",
    "results = results.reset_index()\n",
    "\n",
    "ax = sns.pointplot(data = results, x = \"Multiplier for STD\", y=\"Number of overlapping Dimensions\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "columns = ['Seed', 'Multiplier for STD','Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 0\",\"Confusion Matrix\", 'Accuracy', 'Recall', 'Precision', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay#\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\"\"\"\n",
    "The Fritzens-Sanzeno/reduced dataset was published by Grupe, G., Klaut, D., Otto, L., Mauder, M., Lohrer, J., Kröger, P., and Lang, A. (2020).\n",
    "The genesis and spread of the early Fritzens-Sanzeno culture (5th/4th cent. BCE)–Stable\n",
    "isotope analysis of cremated and uncremated skeletal finds. Journal of Archaeological\n",
    "Science: Reports, 29:102121. Publisher: Elsevier.\n",
    "\n",
    "This should be cited accordingly when used\n",
    "\"\"\"\n",
    "# Generate combined results from grid searches\n",
    "# Look at results of gridsearch\n",
    "#grid = load(\"isotope_prediction/parameter_tuning/grid_search_isotope_2-3.pkl\")\n",
    "#grid = load('isotope_prediction/parameter_tuning/grid_search_isotope_1-2.pkl')\n",
    "#grid = load('models/grid_search_isotope_1-2_linear_n100.pkl')\n",
    "\n",
    "# Step 1: Filter rows where 'param_svc__kernel' is 'linear'\n",
    "#linear_df = results[results['param_svc__kernel'] == 'linear']\n",
    "# Step 2: Find duplicates in 'param_svc__C' within the filtered data\n",
    "#duplicates = linear_df.duplicated(subset='param_svc__C')\n",
    "# Combine the duplicate mask with the 'linear' condition back onto the original DataFrame\n",
    "# To get indices of the original DataFrame to drop\n",
    "#indices_to_drop = linear_df[duplicates].index\n",
    "\n",
    "# Step 3: Drop these indices from the original DataFrame\n",
    "#results = results.drop(index=indices_to_drop)\n",
    "\n",
    "grid = load('models/grid_search_isotope_reduced_linear_n100.pkl')\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results = results.sort_values('rank_test_score')\n",
    "#groups = dict(tuple(results.groupby('Group')))\n",
    "results.head(10)\n",
    "\n",
    "grid = load('models/grid_search_isotope_reduced_rbf_n100.pkl')\n",
    "results1 = pd.DataFrame(grid.cv_results_)\n",
    "results1 = results1.sort_values('rank_test_score')\n",
    "results1.head(10)\n",
    "\n",
    "grid = load('models/grid_search_isotope_reduced_poly_n20.pkl')\n",
    "results2 = pd.DataFrame(grid.cv_results_)\n",
    "results2 = results2.sort_values('rank_test_score')\n",
    "results2.head(10)\n",
    "\n",
    "#res = pd.concat([results2.head(2), results.head(2),results1.head(2)], axis=0, ignore_index=True) # Best two per kernel\n",
    "res = pd.concat([results2, results,results1], axis=0, ignore_index=True) # All results\n",
    "res = res.sort_values('mean_test_score', ascending=False)\n",
    "res.head(20)\n",
    "#dump(res, \"models/grid_search_isotope_1-3_combined\")\n",
    "\n",
    "\"\"\"\n",
    "grid = load('models/grid_search_isotope_reduced_poly_n100.pkl')\n",
    "grid = pd.DataFrame(grid.cv_results_)\n",
    "grid = grid[(grid['mean_test_score'].isna()) ]\n",
    "grid.sort_values('param_svc__gamma')\n",
    "\"\"\"\n",
    "\"\"\"# Read Isotope Data Set\n",
    "isodata = pd.read_csv(\"dataset\")\n",
    "# Create Groups for North of Alps, Inneralpine, and southern Tirol\n",
    "site_group = pd.DataFrame(isodata[\"site code\"].values /100)\n",
    "isodata['site group'] = site_group\n",
    "isodata['site group'] = isodata['site group'].astype('int64')\n",
    "cols = [\"87Sr/86Sr\", \"208Pb/204Pb\", \"207Pb/204Pb\", \"206Pb/204Pb\", \"208Pb/207Pb\", \"206Pb/207Pb\"]\n",
    "\n",
    "# Select two groups\n",
    "isodata = isodata.query('`site group` == 1 | `site group` == 2')\n",
    "isodata.loc[isodata['site group'] == 1, 'site group'] =0\n",
    "isodata.loc[isodata['site group'] == 2, 'site group'] =1\n",
    "\n",
    "scaler = MinMaxScaler() #Can be changed to robustscaler or standardscaler\n",
    "\n",
    "\n",
    "\n",
    "# Scaling adjusted before splitting\n",
    "isodata[cols] = scaler.fit_transform(isodata[cols])\n",
    "\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (grid.best_params_, grid.best_score_)\n",
    ")\n",
    "predictions = grid.predict(isodata[cols])\n",
    "print(classification_report(isodata['site group'],predictions))\n",
    "cm = confusion_matrix(isodata['site group'], predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reduced isotope dataset prediction\n",
    "from joblib import load\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.container import BarContainer\n",
    "models = load('isotope_prediction/models/best_models_reduced_dataset.pkl')\n",
    "result = load('isotope_prediction/predictions/reduced_datasetKernel: rbf C: 100 Gamma: scale.pkl')\n",
    "result = load('isotope_prediction/predictions/reduced_dataset.pkl')\n",
    "cols = result.columns\n",
    "\"\"\"\n",
    "The Fritzens-Sanzeno/reduced dataset was published by Grupe, G., Klaut, D., Otto, L., Mauder, M., Lohrer, J., Kröger, P., and Lang, A. (2020).\n",
    "The genesis and spread of the early Fritzens-Sanzeno culture (5th/4th cent. BCE)–Stable\n",
    "isotope analysis of cremated and uncremated skeletal finds. Journal of Archaeological\n",
    "Science: Reports, 29:102121. Publisher: Elsevier.\n",
    "\n",
    "This should be cited accordingly when used\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "result = result.sort_values(by=['Earliest positive Prediction at Multiplier'], ascending=False).head(50)\n",
    "#result[['Migrant','Earliest positive Prediction at Multiplier']]\n",
    "plot_data = result.loc[result['Earliest positive Prediction at Multiplier'] != -1].sort_values(by=['Earliest positive Prediction at Multiplier'], ascending=False)\n",
    "ax = sns.barplot(plot_data, y='Burial', x='Earliest positive Prediction at Multiplier', hue='Migrant')\n",
    "#plt.figure(figsize=(100,8))\n",
    "#plt.xticks(rotation=45)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=5)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# For best 10\n",
    "\n",
    "# Create Plot based on average Rank with new logarithmic grid\n",
    "m1 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 265608778.2946684 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m2 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 351119173.4215127 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m3 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 613590727.3413188 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m4 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 1072267222.0103253 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m5 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 1873817422.8603868 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m6 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 2477076355.991714 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m7 = load(\"/isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 3274549162.877732 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m8 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 4328761281.083061 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m9 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 5722367659.35022 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "m10 = load(\"isotope_prediction/predictions/reduced_dataset_exhaustive_gridKernel: rbf C: 10000000000.0 Gamma: 3.5111917342151347e-06.pkl\")\n",
    "\n",
    "m1[\"rank1\"] = m1[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank2\"] = m2[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank3\"] = m3[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank4\"] = m4[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank5\"] = m5[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank6\"] = m6[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank7\"] = m7[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank8\"] = m8[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank9\"] = m9[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank10\"] = m10[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"Average Rank\"] = m1[[\"rank1\", \"rank2\", \"rank3\", \"rank4\", \"rank5\", \"rank6\", \"rank7\", \"rank8\", \"rank9\", \"rank10\"]].mean(axis=1)\n",
    "m1[[\"rank1\", \"rank2\", \"rank3\", \"rank4\", \"rank5\", \"rank6\", \"rank7\", \"rank8\", \"rank9\", \"rank10\", \"Average Rank\"]]\n",
    "print(m1[\"Average Rank\"])\n",
    "\"\"\"\n",
    "\n",
    "# For best 2 per kernel\n",
    "# Best 2 per Kernel reduced dataset\n",
    "m1 = load('isotope_prediction/predictions/reduced_dataset_exhaustive_grid_best_2_per_kernelKernel: linear C: 705.4802310718645 Gamma: nan.pkl')\n",
    "m2 = load('isotope_prediction/predictions/reduced_dataset_exhaustive_grid_best_2_per_kernelKernel: linear C: 932.60334688322 Gamma: nan.pkl')\n",
    "m3 = load('isotope_prediction/predictions/reduced_dataset_exhaustive_grid_best_2_per_kernelKernel: poly C: 0.7847599703514611 Gamma: 3.792690190732254.pkl')\n",
    "m4 = load('isotope_prediction/predictions/reduced_dataset_exhaustive_grid_best_2_per_kernelKernel: poly C: 1623776.7391887177 Gamma: 0.0069519279617756054.pkl')\n",
    "m5 = load('isotope_prediction/predictions/reduced_dataset_exhaustive_grid_best_2_per_kernelKernel: rbf C: 1072267222.0103253 Gamma: 3.5111917342151347e-06.pkl')\n",
    "m6 = load('isotope_prediction/predictions/reduced_dataset_exhaustive_grid_best_2_per_kernelKernel: rbf C: 5722367659.35022 Gamma: 3.5111917342151347e-06.pkl')\n",
    "\n",
    "m1[\"rank1\"] = m1[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank2\"] = m2[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank3\"] = m3[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank4\"] = m4[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank5\"] = m5[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"rank6\"] = m6[\"Earliest positive Prediction at Multiplier\"].rank(method='min', ascending=False)\n",
    "m1[\"Average Rank\"] = m1[[\"rank1\", \"rank2\", \"rank3\", \"rank4\", \"rank5\", \"rank6\"]].mean(axis=1)\n",
    "\n",
    "\n",
    "# Create barplot of ranks\n",
    "plot_data = m1.sort_values(by=[\"Average Rank\"], ascending=True).reset_index(drop=True)\n",
    "plot_data['order'] = plot_data.index\n",
    "plot_data = plot_data.reset_index()\n",
    "plot_data['index'] = plot_data['index'] + 1\n",
    "plot_data['index'] = plot_data['index'].astype(str)\n",
    "plot_data['Burial_unique'] = plot_data['index'] + \": \" + plot_data['Site'] + \" \" + plot_data['Burial']\n",
    "# Add additional archaeologic context\n",
    "archaeologic_context = pd.read_csv(\"path dataset with additional archaeologic context\")\n",
    "plot_data['Identifier'] = plot_data['Site'] + plot_data['Burial']\n",
    "archaeologic_context['Identifier'] = archaeologic_context['Site'] + archaeologic_context['Burial']\n",
    "archaeologic_context = archaeologic_context[['Identifier', 'Archaeologic Context']]\n",
    "plot_data = plot_data.astype({'Identifier': str})\n",
    "archaeologic_context = archaeologic_context.astype({'Identifier': str, 'Archaeologic Context' : str})\n",
    "\n",
    "plot_data = plot_data.set_index('Identifier').join(archaeologic_context.set_index('Identifier'))\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "max_rank = plot_data['Average Rank'].max()\n",
    "plot_data = plot_data[plot_data['Average Rank'] != max_rank] # Entferne alle mit max Rank - diese wurden nie als Migrant Candidate erkannt\n",
    "\n",
    "plot_data = plot_data.sort_values(by=[\"order\"], ascending=True).reset_index(drop=True)\n",
    "ax = sns.barplot(plot_data, y='Burial_unique', x=\"Average Rank\", hue='Sample Information', dodge=False, errorbar=None)#  order=plot_data.index,\n",
    "# Add hatches based on additional archaeologic context\n",
    "hatch_map = {\n",
    "    \"0\" : \"//\",\n",
    "    \"1\" : None,\n",
    "    \"2\" : \"\\\\\\\\\"\n",
    "}\n",
    "plot_data['Archaeologic Context'] = plot_data['Archaeologic Context'].map(hatch_map)\n",
    "\n",
    "plt.legend(fontsize='xx-large', title_fontsize='xx-large')\n",
    "\n",
    "\n",
    "hatches_list = plot_data['Archaeologic Context'].to_numpy()\n",
    "patches_list = list(ax.patches)\n",
    "num_bars = int(len(patches_list)/3) # if more category change the 3\n",
    "for i,thisbar_hatch in enumerate(ax.patches):\n",
    "    # Set a different hatch for each bar\n",
    "    if i < plot_data.shape[0]:\n",
    "        if i == 14:\n",
    "            print('2')\n",
    "        hatch = plot_data['Archaeologic Context'].to_numpy()[i]\n",
    "        thisbar_hatch.set_hatch(hatch) # Each Category needs to be colored: First Group\n",
    "        patches_list[i].set_hatch(hatch)\n",
    "        patches_list[i+num_bars].set_hatch(hatch) # Second Group\n",
    "        patches_list[i+(2*num_bars)].set_hatch(hatch) # Third Group\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ax.set_xticklabels(plot_data[\"Average Rank\"])\n",
    "ax.set_ylabel(\"Burial\")\n",
    "plt.xlabel(\"Average Rank\", fontsize=20)\n",
    "plt.ylabel(\"Burial\", fontsize=20)\n",
    "#selection = plot_data.head(34)\n",
    "plt.show()\n",
    "dump(plot_data, \"isotope_prediction/datasets/Fritzens_Sanzeno_Candidates.pkl\")\n",
    "\n",
    "\"\"\"\n",
    "# Select all samples that have been predicted as migrants at some point\n",
    "plot_data[plot_data['Average Rank'] < plot_data['Average Rank'].max()]\n",
    "labeled = plot_data[plot_data['Average Rank'] < plot_data['Average Rank'].max()]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Create pairplot of results\n",
    "unscaled_isodata = pd.read_csv(\"path to dataset fritzens sanzeno\")\n",
    "unscaled_isodata['Average Rank'] = plot_data['Average Rank']\n",
    "# Define marker styles \"Circle\", \"Square\", \"Diamond\"\n",
    "marker_styles = ['o', 's', 'D']  \n",
    "# Map species to marker styles  (read again as  \"Circle\", \"Square\", \"Diamond\")\n",
    "species_to_marker = {0: 'o', 1: 'D'}\n",
    "unscaled_isodata['markers'] = unscaled_isodata['site group'].map(species_to_marker)\n",
    "# Pass marker style column to scatterplot arguments\n",
    "# This sort of works:  at least maps the variable to the default marker style:\n",
    "scatter_kws = {'s': 100, 'alpha': 0.8, 'style': unscaled_isodata['site group'], 'markers': species_to_marker}  # 'style' assigns DEFAULT markers which can be interpreted as \"circle, x, square\"  \n",
    "\n",
    "cols = [\"87Sr/86Sr\", \"208Pb/204Pb\", \"207Pb/204Pb\", \"206Pb/204Pb\", \"208Pb/207Pb\", \"206Pb/207Pb\"]\n",
    "p = sns.pairplot(unscaled_isodata, vars =cols, hue=\"Average Rank\", plot_kws=scatter_kws)#, hue='site group')\n",
    "\n",
    "# ensure axes match on each pairplot\n",
    "for ax in p.axes.flatten():\n",
    "    xlab = ax.get_xlabel()\n",
    "    if len(xlab)==0: continue\n",
    "    ax.set_xlim([unscaled_isodata[xlab].min() - unscaled_isodata[xlab].std(),unscaled_isodata[xlab].max() + unscaled_isodata[xlab].std()])\n",
    "\n",
    "    ylab = ax.get_ylabel()\n",
    "    if len(ylab)==0: continue\n",
    "    ax.set_xlim([unscaled_isodata[xlab].min() - unscaled_isodata[xlab].std(),unscaled_isodata[xlab].max() + unscaled_isodata[xlab].std()])\n",
    "\n",
    "\n",
    "lims_by_col = {'87Sr/86Sr':[0.708, 0.724]}#, \"208Pb/204Pb\":[37.9, 39], \"207Pb/204Pb\":[,15.725]}\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# ensure axes match on each pairplotplt.legend(title='Team', fontsize='medium', title_fontsize='x-large')\n",
    "for ax in p.axes.flatten():\n",
    "    xlab = ax.get_xlabel()\n",
    "    if len(xlab)==0: continue\n",
    "    if xlab == '87Sr/86Sr':\n",
    "        ax.set_xlim([lims_by_col[xlab]])\n",
    "\n",
    "    ylab = ax.get_ylabel()\n",
    "    if len(ylab)==0: continue\n",
    "    if xlab == '87Sr/86Sr':\n",
    "        ax.set_xlim(lims_by_col[ylab])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#results = load('experiment_result/experiment01_groups_of_years_seeds_multiplier_1_5.pkl')\n",
    "# columns = ['Seed', 'Samples', 'Accuracy', 'Recall', 'Precision', 'Score']\n",
    "#results = load('experiment_result/experiment01_real_gaussian_C1.pkl')\n",
    "print(results.copy().groupby(['Multiplier for STD']).mean())\n",
    "print(results.copy().groupby(['Multiplier for STD']).mean().groupby(['Seed']).mean())\n",
    "#sns.barplot(results, x='Samples', y='Recall')\n",
    "#plt.show()\n",
    "#cols = ['Start_Year', 'End_Year']\n",
    "#results['Years'] = results[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "results = results.drop(columns=['Seed','Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 0\",\"Confusion Matrix\"])\n",
    "results = results.rename(columns={\"Score\": \"F1-Score\"})\n",
    "#results = results[results['Samples']<1000]\n",
    "results = results.groupby(['Multiplier for STD']).mean()\n",
    "results = results.reset_index()\n",
    "print(results)\n",
    "\n",
    "#sns.pointplot(data = results, x=results.index, y='F1-Score')\n",
    "#sns.pointplot(data = results, x=results.index, y='Recall')\n",
    "ax = sns.pointplot(data = pd.melt(results, ['Multiplier for STD'], var_name = 'Metric', value_name = 'Score'), x='Multiplier for STD', y='Score', hue='Metric')\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "#ax.set(ylim=(0.5, 1.01))\n",
    "plt.xticks(rotation=45)\n",
    "#ax.set_xticks(['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000'])\n",
    "#ax.set_xticks(range(13), labels=['25','50','100','200','500','1000','10000','25000', '50000', '75000', '100000', '150000', '250000']) # <--- set the ticks first\n",
    "plt.show()\n",
    "\n",
    "columns = ['Seed', 'Multiplier for STD','Trace Cluster 0', \"Trace Cluster 1\",\"Determinant Cluster 0\", \"Determinant Cluster 0\",\"Confusion Matrix\", 'Accuracy', 'Recall', 'Precision', 'Score']\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
